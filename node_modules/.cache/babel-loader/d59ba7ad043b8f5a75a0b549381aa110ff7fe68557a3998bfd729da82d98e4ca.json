{"ast":null,"code":"var _jsxFileName = \"/Users/rashed.alaleeli/Documents/GitHub/portfolio-react/src/container/Researches/ComputerVisionResearch.js\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nexport default function ComputerVisionResearch() {\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: [/*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"Abstract\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 5,\n        columnNumber: 17\n      }, this), \" - The research paper aims to explore the use of Convolutional Neural Networks (CNNs) in building image classification and segmentation networks that will be applied to the Oxford flower dataset. The dataset consists of 17 flower classes, with 80 images for each category, that was used for image classification. While image segmentation was trained only on a single flower class which is the Daffodil flower and it consists of 71 labeled images. The use of transfer learning techniques and pre-trained models were employed for image classification and achieved an accuracy of 89.22%. Alternatively, developed a CNN model to perform image segmentation and it attained an accuracy of 81.101% on unseen data.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 4,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Image classification is defined as the process of labeling an image, those labels are categorized according to the information collected from the images. While Image segmentation is the task of dividing an image into parts or regions which are called segments, the partitioning is based on features of the pixels. Multiple techniques can perform such tasks, but deep learning is the best for these tasks since it employs CNNs to extract and learn features from the images. The models consist of numerous layers each extracting various characteristics from the input image.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 12,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Image classification and segmentation using deep learning have been a part of Computer Vision since 1990. LeNet was initially introduced in that year and was proposed by LeCun [1], that advancement began a new era for CNNs, and numerous models were developed in the years to come. AlexNet, VGG19, ResNet-18, Inception, and Darknet-53 are some of the models that were built and trained on the LSVRC ImageNet dataset [2]. ResNet is one of the highest-performing models with the lowest error rate of 3.57 %, it was developed by K. He, X. Zhang, S. Ren, and J. Sun in 2015, the model comprises up to 152 layers consisting of convolutional layers, max pooling layer, and an average pooling layer [3]. Although, the architecture of the model is very complex making it computationally expensive and hard to train.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 19,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Transfer learning is the concept of utilizing pre-existing models that were trained on a huge dataset and retraining them on a new dataset, it can be used to perform both tasks with better performance than building a new model while saving training time. This idea was implemented in this research to execute the task of classification using the Darknet-53 network. The model was first introduced in 2018 by J. Redmon and A. Farhadi, who intended to enhance YOLO by combining YOLOv2, Darknet-19, and some of the Resnet approach, which resulted in a new network called Darknet-53 that consists of 53 different convolutional layers. The model has the same accuracy and performance as Resnet, however, it is two times faster to train and more efficient, this is because the model has fewer layers of 53 while Resnet has 150 [4].\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 27,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"The dataset used to train the models was provided by the University of Oxford, it consists of 17 different types of popular flowers in the UK, each with 80 images, making it a total of 1360 images, and all images have different characteristics including texture, shape, and colors [5]. All of the images will be used for the classification task, whereas only the Daffodil flower will be used for the segmentation.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 35,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"The research will look into the methodology of classifying and segmenting the images, which starts by organizing the given data, then pre-processing the images to split them into train and validation. Following that, models will be trained using the training data and evaluate how they perform using the validation data. For classification, image labels will be presented as a title for them, while segmentation, will be demonstrated as colored regions for each individual class.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 40,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true);\n}\n_c = ComputerVisionResearch;\nvar _c;\n$RefreshReg$(_c, \"ComputerVisionResearch\");","map":{"version":3,"names":["ComputerVisionResearch","_jsxDEV","_Fragment","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/rashed.alaleeli/Documents/GitHub/portfolio-react/src/container/Researches/ComputerVisionResearch.js"],"sourcesContent":["export default function ComputerVisionResearch() {\n    return (\n        <>\n            <p>\n                <b>Abstract</b> - The research paper aims to explore the use of Convolutional Neural Networks (CNNs) in building image classification\n                and segmentation networks that will be applied to the Oxford flower dataset. The dataset consists of 17 flower classes,\n                with 80 images for each category, that was used for image classification. While image segmentation was trained only on a single\n                flower class which is the Daffodil flower and it consists of 71 labeled images. The use of transfer learning techniques and pre-trained\n                models were employed for image classification and achieved an accuracy of 89.22%. Alternatively, developed a CNN model to perform\n                image segmentation and it attained an accuracy of 81.101% on unseen data.\n            </p>\n            <p>\n                Image classification is defined as the process of labeling an image, those labels are categorized according to the information\n                collected from the images. While Image segmentation is the task of dividing an image into parts or regions which are called segments,\n                the partitioning is based on features of the pixels. Multiple techniques can perform such tasks, but deep learning is the best for\n                these tasks since it employs CNNs to extract and learn features from the images. The models consist of numerous layers each extracting\n                various characteristics from the input image.\n            </p>\n            <p>\n                Image classification and segmentation using deep learning have been a part of Computer Vision since 1990. LeNet was initially introduced\n                in that year and was proposed by LeCun [1], that advancement began a new era for CNNs, and numerous models were developed in the years to come.\n                AlexNet, VGG19, ResNet-18, Inception, and Darknet-53 are some of the models that were built and trained on the LSVRC ImageNet dataset [2].\n                ResNet is one of the highest-performing models with the lowest error rate of 3.57 %, it was developed by K. He, X. Zhang, S. Ren, and J. Sun in 2015,\n                the model comprises up to 152 layers consisting of convolutional layers, max pooling layer, and an average pooling layer [3].\n                Although, the architecture of the model is very complex making it computationally expensive and hard to train.\n            </p>\n            <p>\n                Transfer learning is the concept of utilizing pre-existing models that were trained on a huge dataset and retraining them on a new dataset,\n                it can be used to perform both tasks with better performance than building a new model while saving training time. This idea was implemented\n                in this research to execute the task of classification using the Darknet-53 network. The model was first introduced in 2018 by J. Redmon and A. Farhadi,\n                who intended to enhance YOLO by combining YOLOv2, Darknet-19, and some of the Resnet approach, which resulted in a new network called Darknet-53\n                that consists of 53 different convolutional layers. The model has the same accuracy and performance as Resnet, however, it is two times faster\n                to train and more efficient, this is because the model has fewer layers of 53 while Resnet has 150 [4].\n            </p>\n            <p>\n                The dataset used to train the models was provided by the University of Oxford, it consists of 17 different types of popular flowers in the UK, \n                each with 80 images, making it a total of 1360 images, and all images have different characteristics including texture, shape, and colors [5]. \n                All of the images will be used for the classification task, whereas only the Daffodil flower will be used for the segmentation.\n            </p>\n            <p>\n                The research will look into the methodology of classifying and segmenting the images, which starts by organizing the given data, \n                then pre-processing the images to split them into train and validation. Following that, models will be trained using the training data \n                and evaluate how they perform using the validation data. For classification, image labels will be presented as a title for them, while segmentation, \n                will be demonstrated as colored regions for each individual class.\n            </p>\n        </>\n    );\n}\n"],"mappings":";;;AAAA,eAAe,SAASA,sBAAsBA,CAAA,EAAG;EAC7C,oBACIC,OAAA,CAAAC,SAAA;IAAAC,QAAA,gBACIF,OAAA;MAAAE,QAAA,gBACIF,OAAA;QAAAE,QAAA,EAAG;MAAQ;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,ssBAMnB;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAMH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAOH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAOH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAKH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC;EAAA,eACN,CAAC;AAEX;AAACC,EAAA,GA/CuBR,sBAAsB;AAAA,IAAAQ,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}