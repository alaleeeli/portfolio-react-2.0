{"ast":null,"code":"var _jsxFileName = \"/Users/rashed.alaleeli/Documents/GitHub/portfolio-react/src/container/Researches/DataScienceResearch.js\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nexport default function DataScienceResearch() {\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: [/*#__PURE__*/_jsxDEV(\"span\", {\n      className: \"flex text-center justify-center\",\n      children: /*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"Abstract\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 4,\n        columnNumber: 63\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 4,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Monitoring a water pump's functionality is, or at least should be, as important as building one. There is a relationship between the quality of water in a country and the quality of life there. Whilst more economically developed countries (MEDCs) have an effective way of monitoring water pumps\\u2019 functionality and ensuring that water is consistently clean, developing countries such as Tanzania, do not yet have these same systems imposed and therefore may not regularly check their functionality. Our project focuses on analysing fea- tures that affect water pumps in Tanzania and utilising machine learning classification models and data provided by the Taarifa water points, to predict their functionality. The research results show that random forest is the best-performing classifier to predict the labels with an accuracy of 81.07%, those findings have significant implications for the management of water pumps and help to ensure efficient and effective access to water.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 5,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 12,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"span\", {\n      className: \"flex text-center justify-center\",\n      children: /*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"I. Introduction\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 13,\n        columnNumber: 63\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 13,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Water is an important resource for all living organisms and plays a vital role in economic activities such as agriculture. Throughout the years demand for water has been increasing, but not all countries have effective measures in place to ensure their supply is equilibrium to the demand. This is highlighted more in developing countries such as Tanzania, where there is an escalated demand for water due to rapid urbanization and climate change impacts [1]. Water pumps had been previously introduced in Tanzania, to increase the water supply, although there has been a lack of sufficient monitoring of these pumps to ensure they are functioning as they should be. As of 2015, 29% of the water pumps in Tanzania are not functional, this can be due to several characteristics such as funder, location of the water point, and its age [2]. This research aims to focus on identifying the important features, in predicting the status of a pump and investigate the best-performing classification models by training them on the data and features provided to predict the labels of unseen data. Predicting the functionality, in advance can offer a number of advantages, including lower emergency repair costs, more effective implementation of infrastructure development projects, and most importantly, assuring a steady supply of water.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 14,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Data wrangling is a critical step in ensuring that models offer predictions as effectively as possible, this can be done by handling outliers, incorrect and missing values. Because some features are repetitive and others do not provide useful infor- mation, it is vital to select features that play a substantial role in increasing the model's performance. After data wrangling, experimented with different feature engineering techniques, to ensure that the data set is in the right format, such as ensuring all input variables are numerical variables, and then using var- ious classification models: Random forest, XGboost, logistic regression, and Gaussian Na ive Bayes (GNB) to predict the functionality of the water pump, and evaluate these models. In doing this we were able to investigate important research questions: (i) Which classification models perform best to predict functionality? (ii) How accurately can we predict the functioning of a pump in Tanzania based on its age?\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 23,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 30,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"span\", {\n      className: \"flex text-center justify-center\",\n      children: /*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"II. Literature Review\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 31,\n        columnNumber: 63\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 31,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Drawing from wider research, one hot encoding has been a successful method in converting categorical variables to numerical ones. Although some parts of the research were not relevant, the performance of one hot encoding has been evaluated against other feature engineering approaches like feature hashing. It was a common result for one hot encoding to have the best performance regardless of the model with a PR-AUC of 0.730 and 0.728, over other feature engineering methods such as feature hashing with a PR-AUC score of 0.600 and 0.691 [3]. Due to the large sample size, feature selection methods were also important in [4] [5] [6], which explores the benefit of these methods, including, less chance of over-fitting, and reducing dimensionality reduction as well as the different approaches that one can take to handle this problem. In this paper, a key part of our feature selection approach stems from [7], where results show that a feature selection based on gini importance poses a huge benefit in identifying the optimal subset of features and dimensionality reduction of the data set as well as eliminating noise from the classification task. In the studies that are directly related to predicting a water pump's functionality, a common model that has consistently performed well is XGboost. The model has been the best performing, with over 80% accuracy score [8] [9]. In another study, the focus was on using decision trees, neural networks, and random forests, as the different predictive models, where the random forest was the best-performing model [10]. Our work builds on these different papers as we contrast different methods, for instance, one hot encoding was used to convert categorical variables to numerical variables, and control the input variables into our algorithm through feature selection. We have also utilised both XGboost and Random forest classifiers to predict the status group as well other machine learning models such as Gaussian Naive Bayes.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 32,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"span\", {\n      className: \"flex text-center justify-center\",\n      children: /*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"III. Methodology\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 44,\n        columnNumber: 63\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 44,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"The research workflow followed a precise path, as shown in Figure 2. Understanding the dataset was a critical step in exploring the data and detecting any trends or relationships between the attributes before proceeding with any analysis. Following that, data preprocessing consists of several phases, including handling missing values, handling outliers, and normalising. Then, data was visualised to investigate further correlations and which features influence the water pump's operation. These features will then be chosen based on their importance and potential impact on model performance. Be- fore training the models, all categorical features must be transformed into numerical ones. Several classification models will then be produced in order to determine the best-performing one, and the condition of the water pumps from the test set will be predicted using that model.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 45,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 51,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"Dataset\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 53,\n        columnNumber: 17\n      }, this), \" - The dataset was collected by the Tanzanian Ministry of Water and Taarifa waterpoints dashboard. The dataset initially consisted of three different datasets, training labels, attributes, and test attributes. This led to two different ways to treat this dataset where one method concatenated both datasets and created a new column named 'indic' to distinguish them and guarantee that no samples were jumbled. Therefore had approximately 70000 samples from both training and testing, as well as 39 features that will help with predicting the labels. The other method focused on pre-processing these datasets as two separate datasets: training data with 59400 training data, and 40 attributes, whilst the test data had 14851 instances and 38 attributes as no target variable had been provided. The target variable was the status of the water pump, whether it could have been functional, non-functional, or needed repair.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 52,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 58,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"Data preprocessing\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 60,\n        columnNumber: 17\n      }, this), \" - After going through the data to gather information about it, various columns were discarded as they were redundant features. Features were classified to be redundant if: they just had one unique value for all instances, the feature had no explanation, and features were duplicated. Because the duplicate columns contain the same unique value and the only variation between them is the spelling of these values, one of them will be dropped. A different approach was used for the numerical features where a correlation heat map was drawn to identify numerical variables which were similar, and therefore could also drop one of these variables to avoid overfitting such as 'region code' and 'district code', which had the highest correlation of 0.68.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 59,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"To handle outliers one way was to proceed through all numerical features to count the number of outliers each feature has. Most of the values that are less than the quantile 5% or above the quantile 95% have been replaced with a null value so that they are replaced with an appropriate value when dealing with missing values in the dataset. But for some features, did not use the quantile percentage to remove the outliers, because the quantile percentage was close to the mean value of the feature, so instead used a value that is higher than the percentage just to make sure that this does not affect the distribution of the feature.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 65,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"An alternative approach to handle outliers in each numerical column. Where calculating the kurtosis and skewness of the data elucidated the outliers in the 'amount tsh' and 'population' columns. The 5% outliers for both features were treated by setting them to be missing values. A major difference in this approach was using the less than or equal to signal for these columns as the 5% quantile was equal to the minimum value and therefore just using the less than approach would not change the minimum value, and would still be 0. For features where kurtosis was not high, the instances below the 5% and above 95% quantile were replaced with these values respectively rather than missing value, this adapts the winsorization approach, aiming to replace these outliers with the nearest non-outlying outlier and therefore not affecting the data distribution as much. As part of handling outliers the 'region code' had outliers, upon further investigation, it was clear that these values were imputed wrongly, such as using 60 instead of 6, these errors were handled, by ensuring values with a code above 31 would be corrected, as the maximum for Tanzania is 31. These region codes above 31 had other codes which were a more viable option, as they had a greater mode, and were also less than 31, and therefore assigned these as the unique values for the region, ensuring each region had exactly one unique code. From plotting the longitude and latitude on the Tanzanian map, it appeared that some points were plotted far from Tanzania; and these were the same points that were shown to be an outlier in the boxplot. After investigating those values, it was discovered that more than 2200 samples have a longitude of 0.0 and a latitude of -2.0e-8, and these coordinates were in the Gulf of Guinea; therefore, these values were dropped as they were incorrect values.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 70,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"An approach to dealing with missing values differed based on the feature type. There were not many missing values in numerical features, therefore replaced with their mean value, and that approach wouldn't impact their distribution greatly. Replaced missing values in boolean features like with the most frequent value in that feature. Also, 'scheme name' was dropped since most of it was missing.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 80,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"In contrast, for categorical features, introduced a different technique, defining a function that would preserve the top five most common values while replacing the rest unique values with 'other' and missing values with 'unknown'. There were features with a value of none or None; based on the feature, it was determined to eliminate the instances or the column if it contains numerous none values and would not impact the model's performance.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 84,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"The construction year feature has many samples with zeros, which is an anomaly for the years and was considered as missing values. To handle those values, Defined a new column named 'age since recorded' that will calculate the age using the information given. Following that, defined a function that will compute the age and return a missing value if the construction year equals zero, otherwise, it will return the subtraction of the recorded year and construction year. When looking at the unique values of the new feature, found that there are ages below zero, which is unusual. After investigating these ages, discovered that the recorded year is older than the construction year, which does not make sense, therefore eliminated these instances. And the missing values were replaced by an age that is far from the unique values to distinguish them from the others, as it would be inappropriate to replace them with their mean values because more than 30% of the values in the feature are missing, and that approach would change the distribution of the ages.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 88,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Another approach applied to deal with missing values, was first to handle categorical variables with missing data. A major difference in handling categorical data was the number to be used as the most common. The k value to be used for the most common varied with each feature, where it was decided based on where there was a maximum difference in mode, between k and k-1, and therefore some features would keep the 9 most important values, whilst others would keep the 6 most important values and set the rest to other. In handling numerical data, different conditions were made in how to handle them. Where handling the 'amount tsh' varied on several conditions, as contextually these are factors that could affect the feature. The same principle applied for filling in other features although different conditions were used.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 95,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"In dealing with construction years, an alternative approach was implemented, by using the KNNImputer to replace the missing values with the median value of their k-nearest neigh- bor. To optimise K, GridSearchCV was used and provided a value of 3. After KNNImputer was used to calculate the miss- ing years, a new feature column was created 'pump's age', which was calculated through the difference in the construction year and the year recorded. Several formatting and prepos- sessing were done in this stage to ensure, the year could be extracted and also for any age below 0 to be dropped, as this would not be possible in this context, as it would elucidate that the pump had not been built.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 101,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 106,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"Scaling data\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 108,\n        columnNumber: 17\n      }, this), \" - he usage of normalisation was based on the model's performance, min-max normalisation was employed using equation (1), to normalise both the water amount and the population. Just these columns were considered for normalisation since the other numerical features are location-related and normalising them might modify the process of visualising them later.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 107,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Standard scaling using equation (2) was another approach to transform the data. The dataset consisted of numerical and categorical columns, that have instance values between 0-3500, so standard scaling was used to ensure all features had similar weighting when used for feature selection.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 111,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 115,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"Data visualization\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 117,\n        columnNumber: 17\n      }, this), \" - The data was visualised to investigate the link between the age of the water pump and its functioning. As shown in Figure 4, ages were classified into different groups, and the percentage of functionality for each group was calculated. It is clear that as the pumps get older, the percentage of them being non-functional increases; for example, 26.1% of pumps between the ages of 0 and 10 are non-functional, while 66.7% of pumps between the ages of 41 to 50 are non-functional. Unknown ages that were substituted with the age of 60, have almost the same distribution as years 11 to 20.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 116,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 121,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"Feature engineering and selection\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 123,\n        columnNumber: 17\n      }, this), \" - Categorical features must be translated into numerical val- ues before training classification models. This was achieved by first identifying features with a large number of unique values like 'subvillage' which has 18567; these were dropped, while attributes with a lower number of unique values were used. To convert those features, used ordinal encoding where each unique value in an attribute will be mapped to a numerical value. This approach was used on both the training and testing datasets. Following that, used the f regression feature selection method, which ranked the features in the same order as if they were positively correlated, and then chose the top ten. Data were split into training and test sets, using a ratio of 70-30 based on research provided by the University of Texas which states that the model performs best when a 70-80% split is used for training and 30-20% of the data is used for testing [11].\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 122,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Another approach to converting categorical variables was to use one-hot encoding for nominal features. Using one-hot en- coding over ordinal mapping for nominal features was because the value for these instances had no rank, and so using one-hot encoding ensures that there is no implied ordinal relationship. Using this method increased the feature space for this data set, and therefore to reduce this, feature selection was applied to narrow the feature space to only using features above a certain threshold of 0.027. The importance of each feature was calculated using random forest and is measured as the averaged impurity decrease computed from all decision trees in the forest, without making any assumptions about whether the data is linearly separable or not. The binary classification was converted through a binary mapping function, and ordinal data were converted to numerical data, through ordinal mapping, where the values that were set as other were always 0, and then the mode of each feature would be allocated the highest number.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 128,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 134,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"classification models\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 136,\n        columnNumber: 17\n      }, this), \" - Several classification models were used in this paper: from ensemble algorithms to probabilistic algorithms, neural net- works, and supervised learning algorithms, each with its own set of parameters and trained on various attributes. Began with a decision tree but before training, performed hyperparameter tuning via grid search to determine the ideal parameters for the model and discovered that the model performs best on training with a maximum depth of 20 and minimum sample leaf of 10. As in Figure 5, plotted the scores at different depths by calculating the accuracy scores on the train and test data, at depth 20 the training score reached nearly 95% and the test score around 75%, indicating that the model performs exceptionally well on the training set but not on the test set, indicating overfitting. And settled on a depth of 8, where both results are practically identical, for optimum precision.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 135,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"While for the random forest classifier, performed parameter tuning via random search instead of grid search since it is more computationally expensive and takes longer to find the ideal parameters. Random search selects a random collec- tion of hyperparameters, including maximum depth, minimum samples leaf, minimum samples split, and the number of estimators, then calculates the score, returning the best set of hyperparameters with the best score as an output. According to the random search, the model works best with 200 estimators, minimum samples split of 4, minimum samples leaf of 2, and max depth of 20. However, after experimenting with parameters manually, found that the model performs better when using 300 estimators.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 141,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Multi-layer Perceptron (MLP) was implemented as another classification model, which is an example of Artificial Neural Networks (ANNs) making the model's neurons fully connected. Prior to training, parameter tuning was a key step to determine the optimal set of parameters that maximises the model's performance. To achieve that, experimented the model with different numbers of neurons, and it performs best with 7 neurons. Next, used a random search to look for the optimal set of parameters, and it was found that the model performs best with logistic as the activation function, maximum iterations of 1000, and alpha of 0.0001.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 146,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Also, tried linear support vector machine (SVM) and logistic regression, but they struggle to perform well on large datasets for a variety of reasons, one of which is that they are computationally expensive because both are linear algorithms that involve the dot product of input features and a weight vector. Another problem is that both models require a linear relationship between the input features and the output variable, which is not always the case in big datasets. It is preferable to implement decision trees, random forest classifiers, or neural networks for these relationships.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 151,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Another classification approach was gradient boosting, which works by merging numerous models to generate a stronger model that reduces the percentage error. Before train- ing the model, parameter tuning was performed via random search, which randomly selects parameters such as the number of estimators, learning rate, maximum features, and maximum depth and returns the parameters that perform the best. From the parameter tuning, 30 estimators and a learning rate of 0.5 will be used for the model. After evaluating the model on both the train and test sets, it appears to perform the same, indicating that there is no overfitting.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 156,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"XGBoost is a more regularized form of gradient boosting and uses advanced regularization (L1 & L2), to improve the generalisation capabilities. Typically it is expected that XGBoosting performs better than gradient boosting. In ad- dition as the number of features (39) is significantly less than the number of training samples XGBoost seems to be an appropriate model to use. A classification probabilistic algorithm was also used to compare the performance using ensemble methods and other types of classification models. Gaussian Naive Bayes (probabilistic model), is a rather simple and efficient model as it does not require any parameters.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 161,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"span\", {\n      className: \"flex text-center justify-center\",\n      children: /*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"IV. Results\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 166,\n        columnNumber: 63\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 166,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"In evaluating steps to achieve results, data preprocessing was essential to remove any outliers, missing and incorrect val- ues. Each dataset implemented different methods for prepro- cessing the data. And, to evaluate that stage, both approaches were trained on the same models with the same parameters, and the accuracies will be used then to evaluate which pre- processing approach performs better. Table I summarises the results obtained, dataset A performs better when trained with most models including, decision tree, random forest, MLP, and logistic regression. However, dataset B outperforms dataset A on linear SVM with an accuracy of 61.2%, while dataset A performs much lower with an accuracy of 35.43%.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 167,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"To evaluate the performance of the models on dataset A, they were trained on different preprocessing approaches which include, using normalisation, and feature selection methods, as in Table I, in order to find the optimal method that maximises the accuracy of models when predicting the labels. After training the models on dataset A, found that random forest classifier have the highest performance on unseen data. The model achieved an accuracy of 91.79% on the training set and 81.07% on the validation set, even though there is a huge difference between the two accuracies which indicated overfitting, but the model's accuracy is the best among all other models. Also, found that tree-based algorithms such as decision tree and random forest does not need data to be normalised since the models perform the same with or without feature scaling, this is due to partitions being made based on relative feature values. On the other hand, MLP performs better when using data with no normalisation and achieved an accuracy of 72.53% on unseen data, as shown in Figure 6, the model can predict functional pumps nearly correctly, and less correctly for non-functional labels as the model predicted 2574 pumps to be functional while they are non-functional. However, the model was not able to predict any labels indicating the pump needs repair which makes it less performing comparing it with the others.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 172,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Linear SVM and logistic regression are less reliable since their performance is so low when predicting labels since they are hard to train on large datasets and require a linear relationship between the input and output. The performance of linear SVM is different each time it was run, and it performs better when normalising the data with an accuracy of 41.52%, and 35.43% when data is not standardised. While logistic regression had a higher accuracy when trained on normal data with an accuracy of 61.18%. Subsequently, using the best- performing model, predicted the labels of instances from the test dataset, but it was not possible to calculate the accu- racy since the original labels were not provided previously. However, to evaluate the result produced a bar plot, as shown in Figure 7, the age groups had the same distribution as the training dataset, which is shown in Figure 4. This answers the first question, making the Random forest classifier the best model to predict the labels.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 179,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"In evaluating the performance of the models on dataset B, they were trained using different processing steps including experimenting with different ways to convert nominal cate- gorical features either through mapping or one hot encoding, how to handle the construction missing value, through using KNNImputer or dropping these values, which then had an effect on the feature importance, as well as experimenting with the different threshold value in feature selection. After training the model, gradient boosting seems to be the best classifier, although the results were very close, with a 0.05% difference between the gradient boosting and random forest classifier. Throughout training all models, the training test consistently performed better than the test accuracy, this highlights overfitting in the model. The models initially there was a difference of more than 5% constant for all models, which also represents overfitting in this model, and further hyperparameter techniques can be used like GridSearch.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 185,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"To answer the first research question, our model was trained using a different number of features, which varied by adjusting the threshold. Through experiments, increasing the features used increased the accuracy as shown in II. All models performed were the highest when setting the threshold value to 0.008. Evidently increasing the features improves the model performance as all model's accuracy was highest using 0.008 threshold value, although increasing the number of features used to train the model, can lead to overfitting and also introduces the problem of the data points becoming sparse and the curse of dimensionality problem. The ensemble methods were the best-performing models, with the random forest classifier having the highest accuracy of 78.78% on dataset B, whereas 81.07% on dataset A. Gaussian Na \\u0308\\u0131ve Bayes (GNB) had the lowest accuracy, so whilst it can be argued that differentiating between the best models to use is not easy, it is clear that GNB would not be used as a predictive model, as it assumes all features are independent of each other, and this leads to inaccurate predictions.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 191,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true);\n}\n_c = DataScienceResearch;\nvar _c;\n$RefreshReg$(_c, \"DataScienceResearch\");","map":{"version":3,"names":["DataScienceResearch","_jsxDEV","_Fragment","children","className","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/rashed.alaleeli/Documents/GitHub/portfolio-react/src/container/Researches/DataScienceResearch.js"],"sourcesContent":["export default function DataScienceResearch() {\n    return (\n        <> \n            <span className=\"flex text-center justify-center\"><b>Abstract</b></span>\n            <p>\n                Monitoring a water pump's functionality is, or at least should be, as important as building one. There is a relationship between the quality of water in a country and the quality of life there. \n                Whilst more economically developed countries (MEDCs) have an effective way of monitoring water pumps’ functionality and ensuring that water is consistently clean, developing countries such as Tanzania, do not yet \n                have these same systems imposed and therefore may not regularly check their functionality. Our project focuses on analysing fea- tures that affect water pumps in Tanzania and utilising machine learning classification \n                models and data provided by the Taarifa water points, to predict their functionality. The research results show that random forest is the best-performing classifier to predict the labels with an accuracy of 81.07%, \n                those findings have significant implications for the management of water pumps and help to ensure efficient and effective access to water.\n            </p>\n            <br />\n            <span className=\"flex text-center justify-center\"><b>I. Introduction</b></span>\n            <p>\n                Water is an important resource for all living organisms and plays a vital role in economic activities such as agriculture. Throughout the years demand for water has been increasing, \n                but not all countries have effective measures in place to ensure their supply is equilibrium to the demand. This is highlighted more in developing countries such as Tanzania, where there is an escalated \n                demand for water due to rapid urbanization and climate change impacts [1]. Water pumps had been previously introduced in Tanzania, to increase the water supply, although there has been a lack of sufficient \n                monitoring of these pumps to ensure they are functioning as they should be. As of 2015, 29% of the water pumps in Tanzania are not functional, this can be due to several characteristics such as funder, \n                location of the water point, and its age [2]. This research aims to focus on identifying the important features, in predicting the status of a pump and investigate the best-performing classification models \n                by training them on the data and features provided to predict the labels of unseen data. Predicting the functionality, in advance can offer a number of advantages, including lower emergency repair costs, \n                more effective implementation of infrastructure development projects, and most importantly, assuring a steady supply of water.\n            </p>\n            <p>\n                Data wrangling is a critical step in ensuring that models offer predictions as effectively as possible, this can be done by handling outliers, incorrect and missing values. Because some features are repetitive \n                and others do not provide useful infor- mation, it is vital to select features that play a substantial role in increasing the model's performance. After data wrangling, experimented with different feature engineering \n                techniques, to ensure that the data set is in the right format, such as ensuring all input variables are numerical variables, and then using var- ious classification models: Random forest, XGboost, logistic regression, \n                and Gaussian Na ive Bayes (GNB) to predict the functionality of the water pump, and evaluate these models. In doing this we were able to investigate important research questions: (i) Which classification models perform \n                best to predict functionality? (ii) How accurately can we predict the functioning of a pump in Tanzania based on its age?\n            </p>\n            <br />\n            <span className=\"flex text-center justify-center\"><b>II. Literature Review</b></span>\n            <p>\n                Drawing from wider research, one hot encoding has been a successful method in converting categorical variables to numerical ones. Although some parts of the research were not relevant, \n                the performance of one hot encoding has been evaluated against other feature engineering approaches like feature hashing. It was a common result for one hot encoding to have the best performance regardless of the \n                model with a PR-AUC of 0.730 and 0.728, over other feature engineering methods such as feature hashing with a PR-AUC score of 0.600 and 0.691 [3]. Due to the large sample size, feature selection methods were also \n                important in [4] [5] [6], which explores the benefit of these methods, including, less chance of over-fitting, and reducing dimensionality reduction as well as the different approaches that one can take to handle \n                this problem. In this paper, a key part of our feature selection approach stems from [7], where results show that a feature selection based on gini importance poses a huge benefit in identifying the optimal subset \n                of features and dimensionality reduction of the data set as well as eliminating noise from the classification task. In the studies that are directly related to predicting a water pump's functionality, a common model \n                that has consistently performed well is XGboost. The model has been the best performing, with over 80% accuracy score [8] [9]. In another study, the focus was on using decision trees, neural networks, and random forests, \n                as the different predictive models, where the random forest was the best-performing model [10]. Our work builds on these different papers as we contrast different methods, for instance, one hot encoding was used to \n                convert categorical variables to numerical variables, and control the input variables into our algorithm through feature selection. We have also utilised both XGboost and Random forest classifiers to predict the \n                status group as well other machine learning models such as Gaussian Naive Bayes.\n            </p>\n            <span className=\"flex text-center justify-center\"><b>III. Methodology</b></span>\n            <p>\n                The research workflow followed a precise path, as shown in Figure 2. Understanding the dataset was a critical step in exploring the data and detecting any trends or relationships between the attributes before proceeding \n                with any analysis. Following that, data preprocessing consists of several phases, including handling missing values, handling outliers, and normalising. Then, data was visualised to investigate further correlations and \n                which features influence the water pump's operation. These features will then be chosen based on their importance and potential impact on model performance. Be- fore training the models, all categorical features must be \n                transformed into numerical ones. Several classification models will then be produced in order to determine the best-performing one, and the condition of the water pumps from the test set will be predicted using that model.\n            </p>\n            <br />\n            <p>\n                <b>Dataset</b> - The dataset was collected by the Tanzanian Ministry of Water and Taarifa waterpoints dashboard. The dataset initially consisted of three different datasets, training labels, attributes, and test attributes. \n                This led to two different ways to treat this dataset where one method concatenated both datasets and created a new column named 'indic' to distinguish them and guarantee that no samples were jumbled. Therefore had approximately \n                70000 samples from both training and testing, as well as 39 features that will help with predicting the labels. The other method focused on pre-processing these datasets as two separate datasets: training data with 59400 training \n                data, and 40 attributes, whilst the test data had 14851 instances and 38 attributes as no target variable had been provided. The target variable was the status of the water pump, whether it could have been functional, non-functional, or needed repair.\n            </p>\n            <br />\n            <p>\n                <b>Data preprocessing</b> - After going through the data to gather information about it, various columns were discarded as they were redundant features. Features were classified to be redundant if: they just had one unique \n                value for all instances, the feature had no explanation, and features were duplicated. Because the duplicate columns contain the same unique value and the only variation between them is the spelling of these values, one of \n                them will be dropped. A different approach was used for the numerical features where a correlation heat map was drawn to identify numerical variables which were similar, and therefore could also drop one of these variables \n                to avoid overfitting such as 'region code' and 'district code', which had the highest correlation of 0.68.\n            </p>\n            <p>\n                To handle outliers one way was to proceed through all numerical features to count the number of outliers each feature has. Most of the values that are less than the quantile 5% or above the quantile 95% have been replaced with \n                a null value so that they are replaced with an appropriate value when dealing with missing values in the dataset. But for some features, did not use the quantile percentage to remove the outliers, because the quantile percentage \n                was close to the mean value of the feature, so instead used a value that is higher than the percentage just to make sure that this does not affect the distribution of the feature.\n            </p>\n            <p>\n                An alternative approach to handle outliers in each numerical column. Where calculating the kurtosis and skewness of the data elucidated the outliers in the 'amount tsh' and 'population' columns. The 5% outliers for both features \n                were treated by setting them to be missing values. A major difference in this approach was using the less than or equal to signal for these columns as the 5% quantile was equal to the minimum value and therefore just using the \n                less than approach would not change the minimum value, and would still be 0. For features where kurtosis was not high, the instances below the 5% and above 95% quantile were replaced with these values respectively rather than \n                missing value, this adapts the winsorization approach, aiming to replace these outliers with the nearest non-outlying outlier and therefore not affecting the data distribution as much. As part of handling outliers the 'region code' \n                had outliers, upon further investigation, it was clear that these values were imputed wrongly, such as using 60 instead of 6, these errors were handled, by ensuring values with a code above 31 would be corrected, as the maximum for \n                Tanzania is 31. These region codes above 31 had other codes which were a more viable option, as they had a greater mode, and were also less than 31, and therefore assigned these as the unique values for the region, ensuring each \n                region had exactly one unique code. From plotting the longitude and latitude on the Tanzanian map, it appeared that some points were plotted far from Tanzania; and these were the same points that were shown to be an outlier in the boxplot. \n                After investigating those values, it was discovered that more than 2200 samples have a longitude of 0.0 and a latitude of -2.0e-8, and these coordinates were in the Gulf of Guinea; therefore, these values were dropped as they were incorrect values.\n            </p>\n            <p>\n                An approach to dealing with missing values differed based on the feature type. There were not many missing values in numerical features, therefore replaced with their mean value, and that approach wouldn't impact their distribution greatly. \n                Replaced missing values in boolean features like with the most frequent value in that feature. Also, 'scheme name' was dropped since most of it was missing. \n            </p>\n            <p>\n                In contrast, for categorical features, introduced a different technique, defining a function that would preserve the top five most common values while replacing the rest unique values with 'other' and missing values with 'unknown'.\n                There were features with a value of none or None; based on the feature, it was determined to eliminate the instances or the column if it contains numerous none values and would not impact the model's performance.\n            </p>\n            <p>\n                The construction year feature has many samples with zeros, which is an anomaly for the years and was considered as missing values. To handle those values, Defined a new column named 'age since recorded' that will calculate the age using \n                the information given. Following that, defined a function that will compute the age and return a missing value if the construction year equals zero, otherwise, it will return the subtraction of the recorded year and construction year. \n                When looking at the unique values of the new feature, found that there are ages below zero, which is unusual. After investigating these ages, discovered that the recorded year is older than the construction year, which does not make sense, \n                therefore eliminated these instances. And the missing values were replaced by an age that is far from the unique values to distinguish them from the others, as it would be inappropriate to replace them with their mean values because more \n                than 30% of the values in the feature are missing, and that approach would change the distribution of the ages.\n            </p>\n            <p>\n                Another approach applied to deal with missing values, was first to handle categorical variables with missing data. A major difference in handling categorical data was the number to be used as the most common. The k value to be used for the \n                most common varied with each feature, where it was decided based on where there was a maximum difference in mode, between k and k-1, and therefore some features would keep the 9 most important values, whilst others would keep the 6 most important \n                values and set the rest to other. In handling numerical data, different conditions were made in how to handle them. Where handling the 'amount tsh' varied on several conditions, as contextually these are factors that could affect the feature. \n                The same principle applied for filling in other features although different conditions were used.\n            </p>\n            <p>\n                In dealing with construction years, an alternative approach was implemented, by using the KNNImputer to replace the missing values with the median value of their k-nearest neigh- bor. To optimise K, GridSearchCV was used and provided a value of 3. \n                After KNNImputer was used to calculate the miss- ing years, a new feature column was created 'pump's age', which was calculated through the difference in the construction year and the year recorded. Several formatting and prepos- sessing were done \n                in this stage to ensure, the year could be extracted and also for any age below 0 to be dropped, as this would not be possible in this context, as it would elucidate that the pump had not been built.\n            </p>\n            <br />\n            <p>\n                <b>Scaling data</b> - he usage of normalisation was based on the model's performance, min-max normalisation was employed using equation (1), to normalise both the water amount and the population. Just these columns were considered for normalisation \n                since the other numerical features are location-related and normalising them might modify the process of visualising them later.\n            </p>\n            <p>\n                Standard scaling using equation (2) was another approach to transform the data. The dataset consisted of numerical and categorical columns, that have instance values between 0-3500, so standard scaling was used to ensure all features had similar \n                weighting when used for feature selection.\n            </p>\n            <br />\n            <p>\n                <b>Data visualization</b> - The data was visualised to investigate the link between the age of the water pump and its functioning. As shown in Figure 4, ages were classified into different groups, and the percentage of functionality for each group \n                was calculated. It is clear that as the pumps get older, the percentage of them being non-functional increases; for example, 26.1% of pumps between the ages of 0 and 10 are non-functional, while 66.7% of pumps between the ages of 41 to 50 are non-functional.\n                Unknown ages that were substituted with the age of 60, have almost the same distribution as years 11 to 20.\n            </p>\n            <br />\n            <p>\n                <b>Feature engineering and selection</b> - Categorical features must be translated into numerical val- ues before training classification models. This was achieved by first identifying features with a large number of unique values like 'subvillage' which has \n                18567; these were dropped, while attributes with a lower number of unique values were used. To convert those features, used ordinal encoding where each unique value in an attribute will be mapped to a numerical value. This approach was used on both the training \n                and testing datasets. Following that, used the f regression feature selection method, which ranked the features in the same order as if they were positively correlated, and then chose the top ten. Data were split into training and test sets, using a ratio of \n                70-30 based on research provided by the University of Texas which states that the model performs best when a 70-80% split is used for training and 30-20% of the data is used for testing [11].\n            </p>\n            <p>\n                Another approach to converting categorical variables was to use one-hot encoding for nominal features. Using one-hot en- coding over ordinal mapping for nominal features was because the value for these instances had no rank, and so using one-hot encoding ensures \n                that there is no implied ordinal relationship. Using this method increased the feature space for this data set, and therefore to reduce this, feature selection was applied to narrow the feature space to only using features above a certain threshold of 0.027. The \n                importance of each feature was calculated using random forest and is measured as the averaged impurity decrease computed from all decision trees in the forest, without making any assumptions about whether the data is linearly separable or not. The binary classification \n                was converted through a binary mapping function, and ordinal data were converted to numerical data, through ordinal mapping, where the values that were set as other were always 0, and then the mode of each feature would be allocated the highest number.\n            </p>\n            <br />\n            <p>\n                <b>classification models</b> - Several classification models were used in this paper: from ensemble algorithms to probabilistic algorithms, neural net- works, and supervised learning algorithms, each with its own set of parameters and trained on various attributes. \n                Began with a decision tree but before training, performed hyperparameter tuning via grid search to determine the ideal parameters for the model and discovered that the model performs best on training with a maximum depth of 20 and minimum sample leaf of 10. As in Figure 5, \n                plotted the scores at different depths by calculating the accuracy scores on the train and test data, at depth 20 the training score reached nearly 95% and the test score around 75%, indicating that the model performs exceptionally well on the training set but not on the \n                test set, indicating overfitting. And settled on a depth of 8, where both results are practically identical, for optimum precision.\n            </p>\n            <p>\n                While for the random forest classifier, performed parameter tuning via random search instead of grid search since it is more computationally expensive and takes longer to find the ideal parameters. Random search selects a random collec- tion of hyperparameters, \n                including maximum depth, minimum samples leaf, minimum samples split, and the number of estimators, then calculates the score, returning the best set of hyperparameters with the best score as an output. According to the random search, the model works best with 200 estimators, \n                minimum samples split of 4, minimum samples leaf of 2, and max depth of 20. However, after experimenting with parameters manually, found that the model performs better when using 300 estimators.\n            </p>\n            <p>\n                Multi-layer Perceptron (MLP) was implemented as another classification model, which is an example of Artificial Neural Networks (ANNs) making the model's neurons fully connected. Prior to training, parameter tuning was a key step to determine the optimal set of parameters \n                that maximises the model's performance. To achieve that, experimented the model with different numbers of neurons, and it performs best with 7 neurons. Next, used a random search to look for the optimal set of parameters, and it was found that the model performs best with \n                logistic as the activation function, maximum iterations of 1000, and alpha of 0.0001.\n            </p>\n            <p>\n                Also, tried linear support vector machine (SVM) and logistic regression, but they struggle to perform well on large datasets for a variety of reasons, one of which is that they are computationally expensive because both are linear algorithms that involve the dot product of \n                input features and a weight vector. Another problem is that both models require a linear relationship between the input features and the output variable, which is not always the case in big datasets. It is preferable to implement decision trees, random forest classifiers, \n                or neural networks for these relationships.\n            </p>\n            <p>\n                Another classification approach was gradient boosting, which works by merging numerous models to generate a stronger model that reduces the percentage error. Before train- ing the model, parameter tuning was performed via random search, which randomly selects parameters such \n                as the number of estimators, learning rate, maximum features, and maximum depth and returns the parameters that perform the best. From the parameter tuning, 30 estimators and a learning rate of 0.5 will be used for the model. After evaluating the model on both the train and \n                test sets, it appears to perform the same, indicating that there is no overfitting.\n            </p>\n            <p>\n                XGBoost is a more regularized form of gradient boosting and uses advanced regularization (L1 & L2), to improve the generalisation capabilities. Typically it is expected that XGBoosting performs better than gradient boosting. In ad- dition as the number of features (39) is \n                significantly less than the number of training samples XGBoost seems to be an appropriate model to use. A classification probabilistic algorithm was also used to compare the performance using ensemble methods and other types of classification models. Gaussian Naive Bayes \n                (probabilistic model), is a rather simple and efficient model as it does not require any parameters.\n            </p>\n            <span className=\"flex text-center justify-center\"><b>IV. Results</b></span>\n            <p>\n                In evaluating steps to achieve results, data preprocessing was essential to remove any outliers, missing and incorrect val- ues. Each dataset implemented different methods for prepro- cessing the data. And, to evaluate that stage, both approaches were trained on the same \n                models with the same parameters, and the accuracies will be used then to evaluate which pre- processing approach performs better. Table I summarises the results obtained, dataset A performs better when trained with most models including, decision tree, random forest, MLP, \n                and logistic regression. However, dataset B outperforms dataset A on linear SVM with an accuracy of 61.2%, while dataset A performs much lower with an accuracy of 35.43%.\n            </p>\n            <p>\n                To evaluate the performance of the models on dataset A, they were trained on different preprocessing approaches which include, using normalisation, and feature selection methods, as in Table I, in order to find the optimal method that maximises the accuracy of models when \n                predicting the labels. After training the models on dataset A, found that random forest classifier have the highest performance on unseen data. The model achieved an accuracy of 91.79% on the training set and 81.07% on the validation set, even though there is a huge difference \n                between the two accuracies which indicated overfitting, but the model's accuracy is the best among all other models. Also, found that tree-based algorithms such as decision tree and random forest does not need data to be normalised since the models perform the same with or without \n                feature scaling, this is due to partitions being made based on relative feature values. On the other hand, MLP performs better when using data with no normalisation and achieved an accuracy of 72.53% on unseen data, as shown in Figure 6, the model can predict functional pumps \n                nearly correctly, and less correctly for non-functional labels as the model predicted 2574 pumps to be functional while they are non-functional. However, the model was not able to predict any labels indicating the pump needs repair which makes it less performing comparing it with the others.\n            </p>\n            <p>\n                Linear SVM and logistic regression are less reliable since their performance is so low when predicting labels since they are hard to train on large datasets and require a linear relationship between the input and output. The performance of linear SVM is different each time it was run, \n                and it performs better when normalising the data with an accuracy of 41.52%, and 35.43% when data is not standardised. While logistic regression had a higher accuracy when trained on normal data with an accuracy of 61.18%. Subsequently, using the best- performing model, predicted the \n                labels of instances from the test dataset, but it was not possible to calculate the accu- racy since the original labels were not provided previously. However, to evaluate the result produced a bar plot, as shown in Figure 7, the age groups had the same distribution as the training \n                dataset, which is shown in Figure 4. This answers the first question, making the Random forest classifier the best model to predict the labels.\n            </p>\n            <p>\n                In evaluating the performance of the models on dataset B, they were trained using different processing steps including experimenting with different ways to convert nominal cate- gorical features either through mapping or one hot encoding, how to handle the construction missing value, \n                through using KNNImputer or dropping these values, which then had an effect on the feature importance, as well as experimenting with the different threshold value in feature selection. After training the model, gradient boosting seems to be the best classifier, although the results were \n                very close, with a 0.05% difference between the gradient boosting and random forest classifier. Throughout training all models, the training test consistently performed better than the test accuracy, this highlights overfitting in the model. The models initially there was a difference of \n                more than 5% constant for all models, which also represents overfitting in this model, and further hyperparameter techniques can be used like GridSearch.\n            </p>\n            <p>\n                To answer the first research question, our model was trained using a different number of features, which varied by adjusting the threshold. Through experiments, increasing the features used increased the accuracy as shown in II. All models performed were the highest when setting the threshold \n                value to 0.008. Evidently increasing the features improves the model performance as all model's accuracy was highest using 0.008 threshold value, although increasing the number of features used to train the model, can lead to overfitting and also introduces the problem of the data points becoming sparse and the curse of dimensionality problem. The ensemble methods were the best-performing models, with the random forest classifier having the highest accuracy of 78.78% on dataset B, whereas 81.07% on dataset A. Gaussian Na ̈ıve Bayes (GNB) had the lowest accuracy, so whilst it can be argued that differentiating between the best models to use is not easy, it is clear that GNB would not be used as a predictive model, as it assumes all features are independent of each other, and this leads to inaccurate predictions.\n            </p>\n\n        </>\n    )\n}"],"mappings":";;;AAAA,eAAe,SAASA,mBAAmBA,CAAA,EAAG;EAC1C,oBACIC,OAAA,CAAAC,SAAA;IAAAC,QAAA,gBACIF,OAAA;MAAMG,SAAS,EAAC,iCAAiC;MAAAD,QAAA,eAACF,OAAA;QAAAE,QAAA,EAAG;MAAQ;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC,eACxEP,OAAA;MAAAE,QAAA,EAAG;IAMH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eACNP,OAAA;MAAMG,SAAS,EAAC,iCAAiC;MAAAD,QAAA,eAACF,OAAA;QAAAE,QAAA,EAAG;MAAe;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC,eAC/EP,OAAA;MAAAE,QAAA,EAAG;IAQH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAMH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eACNP,OAAA;MAAMG,SAAS,EAAC,iCAAiC;MAAAD,QAAA,eAACF,OAAA;QAAAE,QAAA,EAAG;MAAqB;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC,eACrFP,OAAA;MAAAE,QAAA,EAAG;IAWH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAMG,SAAS,EAAC,iCAAiC;MAAAD,QAAA,eAACF,OAAA;QAAAE,QAAA,EAAG;MAAgB;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC,eAChFP,OAAA;MAAAE,QAAA,EAAG;IAKH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eACNP,OAAA;MAAAE,QAAA,gBACIF,OAAA;QAAAE,QAAA,EAAG;MAAO;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,25BAIlB;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eACNP,OAAA;MAAAE,QAAA,gBACIF,OAAA;QAAAE,QAAA,EAAG;MAAkB;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,kvBAI7B;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IASH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAGH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAGH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAMH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAKH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eACNP,OAAA;MAAAE,QAAA,gBACIF,OAAA;QAAAE,QAAA,EAAG;MAAY;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,0WAEvB;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAGH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eACNP,OAAA;MAAAE,QAAA,gBACIF,OAAA;QAAAE,QAAA,EAAG;MAAkB;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,ilBAG7B;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eACNP,OAAA;MAAAE,QAAA,gBACIF,OAAA;QAAAE,QAAA,EAAG;MAAiC;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,u6BAI5C;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAKH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eACNP,OAAA;MAAAE,QAAA,gBACIF,OAAA;QAAAE,QAAA,EAAG;MAAqB;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,u5BAIhC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAMG,SAAS,EAAC,iCAAiC;MAAAD,QAAA,eAACF,OAAA;QAAAE,QAAA,EAAG;MAAW;QAAAE,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC,eAC3EP,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAMH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAKH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAKH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJP,OAAA;MAAAE,QAAA,EAAG;IAGH;MAAAE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC;EAAA,eAEN,CAAC;AAEX;AAACC,EAAA,GArMuBT,mBAAmB;AAAA,IAAAS,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}