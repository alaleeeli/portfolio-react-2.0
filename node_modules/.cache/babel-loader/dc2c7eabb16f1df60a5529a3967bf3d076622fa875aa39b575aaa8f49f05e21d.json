{"ast":null,"code":"var _jsxFileName = \"/Users/rashed.alaleeli/Documents/GitHub/portfolio-react/src/container/Researches/ComputerVisionResearch.js\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nexport default function ComputerVisionResearch() {\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: [/*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"Abstract\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 5,\n        columnNumber: 17\n      }, this), \" - The research paper aims to explore the use of Convolutional Neural Networks (CNNs) in building image classification and segmentation networks that will be applied to the Oxford flower dataset. The dataset consists of 17 flower classes, with 80 images for each category, that was used for image classification. While image segmentation was trained only on a single flower class which is the Daffodil flower and it consists of 71 labeled images. The use of transfer learning techniques and pre-trained models were employed for image classification and achieved an accuracy of 89.22%. Alternatively, developed a CNN model to perform image segmentation and it attained an accuracy of 81.101% on unseen data.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 4,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Image classification is defined as the process of labeling an image, those labels are categorized according to the information collected from the images. While Image segmentation is the task of dividing an image into parts or regions which are called segments, the partitioning is based on features of the pixels. Multiple techniques can perform such tasks, but deep learning is the best for these tasks since it employs CNNs to extract and learn features from the images. The models consist of numerous layers each extracting various characteristics from the input image.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 12,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Image classification and segmentation using deep learning have been a part of Computer Vision since 1990. LeNet was initially introduced in that year and was proposed by LeCun [1], that advancement began a new era for CNNs, and numerous models were developed in the years to come. AlexNet, VGG19, ResNet-18, Inception, and Darknet-53 are some of the models that were built and trained on the LSVRC ImageNet dataset [2]. ResNet is one of the highest-performing models with the lowest error rate of 3.57 %, it was developed by K. He, X. Zhang, S. Ren, and J. Sun in 2015, the model comprises up to 152 layers consisting of convolutional layers, max pooling layer, and an average pooling layer [3]. Although, the architecture of the model is very complex making it computationally expensive and hard to train.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 19,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Transfer learning is the concept of utilizing pre-existing models that were trained on a huge dataset and retraining them on a new dataset, it can be used to perform both tasks with better performance than building a new model while saving training time. This idea was implemented in this research to execute the task of classification using the Darknet-53 network. The model was first introduced in 2018 by J. Redmon and A. Farhadi, who intended to enhance YOLO by combining YOLOv2, Darknet-19, and some of the Resnet approach, which resulted in a new network called Darknet-53 that consists of 53 different convolutional layers. The model has the same accuracy and performance as Resnet, however, it is two times faster to train and more efficient, this is because the model has fewer layers of 53 while Resnet has 150 [4].\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 27,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"The dataset used to train the models was provided by the University of Oxford, it consists of 17 different types of popular flowers in the UK, each with 80 images, making it a total of 1360 images, and all images have different characteristics including texture, shape, and colors [5]. All of the images will be used for the classification task, whereas only the Daffodil flower will be used for the segmentation.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 35,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"The research will look into the methodology of classifying and segmenting the images, which starts by organizing the given data, then pre-processing the images to split them into train and validation. Following that, models will be trained using the training data and evaluate how they perform using the validation data. For classification, image labels will be presented as a title for them, while segmentation, will be demonstrated as colored regions for each individual class.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 40,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"b\", {\n        children: \"methodology\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 47,\n        columnNumber: 17\n      }, this), \" Darknet-53 will be used to perform the classification task, which takes an input image of 256x256x3. 4 random images were selected then to investigate their size, displayed them all together in a single plot with their size, as shown in Figure 2, and found that each image has a different size, while CNN requires all input images to have a similar size, and for darknet-53 images need to be resized to 256x256. Therefore, looped through each image in the datastore and resized them with the desired size then replaced each image with the one in the folder by writing them to the file specified by their name.\"]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 46,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Data then need to be organized into subfolders, each specie should be in a separate folder. Firstly, folders need to be created using the flower's names, but after going through the images discovered that the images were sorted randomly rather than alphabetically. For that reason, defined an array of flower names according to their order in the folder, after looping through the whole folder manually to investigate how they are ordered, then used the array to create the subfolders, those names will be used as labels for the images. Subsequently, moved each image to its corresponding folder, the first 80 images will go to the first folder, and so on, used the modulo to move to the next folder if it equals 0, then images will be moved to the next folder.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 53,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Before retraining the model, data must be split into train and validation. To do so, created an image datastore for the images with their subfolders, which will treat the folders\\u2019 names as a label source. Following that, data were with a 70-30 ratio ensuring that the split is randomized, the ratio was used based on research provided by the University of Texas which says that the model performs best when a 70-80% split is used for training and 30-20% of the data is used for validation [7].\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 60,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true);\n}\n_c = ComputerVisionResearch;\nvar _c;\n$RefreshReg$(_c, \"ComputerVisionResearch\");","map":{"version":3,"names":["ComputerVisionResearch","_jsxDEV","_Fragment","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/rashed.alaleeli/Documents/GitHub/portfolio-react/src/container/Researches/ComputerVisionResearch.js"],"sourcesContent":["export default function ComputerVisionResearch() {\n    return (\n        <>\n            <p>\n                <b>Abstract</b> - The research paper aims to explore the use of Convolutional Neural Networks (CNNs) in building image classification\n                and segmentation networks that will be applied to the Oxford flower dataset. The dataset consists of 17 flower classes,\n                with 80 images for each category, that was used for image classification. While image segmentation was trained only on a single\n                flower class which is the Daffodil flower and it consists of 71 labeled images. The use of transfer learning techniques and pre-trained\n                models were employed for image classification and achieved an accuracy of 89.22%. Alternatively, developed a CNN model to perform\n                image segmentation and it attained an accuracy of 81.101% on unseen data.\n            </p>\n            <p>\n                Image classification is defined as the process of labeling an image, those labels are categorized according to the information\n                collected from the images. While Image segmentation is the task of dividing an image into parts or regions which are called segments,\n                the partitioning is based on features of the pixels. Multiple techniques can perform such tasks, but deep learning is the best for\n                these tasks since it employs CNNs to extract and learn features from the images. The models consist of numerous layers each extracting\n                various characteristics from the input image.\n            </p>\n            <p>\n                Image classification and segmentation using deep learning have been a part of Computer Vision since 1990. LeNet was initially introduced\n                in that year and was proposed by LeCun [1], that advancement began a new era for CNNs, and numerous models were developed in the years to come.\n                AlexNet, VGG19, ResNet-18, Inception, and Darknet-53 are some of the models that were built and trained on the LSVRC ImageNet dataset [2].\n                ResNet is one of the highest-performing models with the lowest error rate of 3.57 %, it was developed by K. He, X. Zhang, S. Ren, and J. Sun in 2015,\n                the model comprises up to 152 layers consisting of convolutional layers, max pooling layer, and an average pooling layer [3].\n                Although, the architecture of the model is very complex making it computationally expensive and hard to train.\n            </p>\n            <p>\n                Transfer learning is the concept of utilizing pre-existing models that were trained on a huge dataset and retraining them on a new dataset,\n                it can be used to perform both tasks with better performance than building a new model while saving training time. This idea was implemented\n                in this research to execute the task of classification using the Darknet-53 network. The model was first introduced in 2018 by J. Redmon and A. Farhadi,\n                who intended to enhance YOLO by combining YOLOv2, Darknet-19, and some of the Resnet approach, which resulted in a new network called Darknet-53\n                that consists of 53 different convolutional layers. The model has the same accuracy and performance as Resnet, however, it is two times faster\n                to train and more efficient, this is because the model has fewer layers of 53 while Resnet has 150 [4].\n            </p>\n            <p>\n                The dataset used to train the models was provided by the University of Oxford, it consists of 17 different types of popular flowers in the UK, \n                each with 80 images, making it a total of 1360 images, and all images have different characteristics including texture, shape, and colors [5]. \n                All of the images will be used for the classification task, whereas only the Daffodil flower will be used for the segmentation.\n            </p>\n            <p>\n                The research will look into the methodology of classifying and segmenting the images, which starts by organizing the given data, \n                then pre-processing the images to split them into train and validation. Following that, models will be trained using the training data \n                and evaluate how they perform using the validation data. For classification, image labels will be presented as a title for them, while segmentation, \n                will be demonstrated as colored regions for each individual class.\n            </p>\n            <p>\n                <b>methodology</b> Darknet-53 will be used to perform the classification task, which takes an input image of 256x256x3. 4 random images were selected \n                then to investigate their size, displayed them all together in a single plot with their size, as shown in Figure 2, and found that each image has a \n                different size, while CNN requires all input images to have a similar size, and for darknet-53 images need to be resized to 256x256. Therefore, \n                looped through each image in the datastore and resized them with the desired size then replaced each image with the one in the folder by writing \n                them to the file specified by their name.\n            </p>\n            <p>\n                Data then need to be organized into subfolders, each specie should be in a separate folder. Firstly, folders need to be created using the flower's names, \n                but after going through the images discovered that the images were sorted randomly rather than alphabetically. For that reason, defined an array of flower \n                names according to their order in the folder, after looping through the whole folder manually to investigate how they are ordered, then used the array to \n                create the subfolders, those names will be used as labels for the images. Subsequently, moved each image to its corresponding folder, the first 80 images \n                will go to the first folder, and so on, used the modulo to move to the next folder if it equals 0, then images will be moved to the next folder.\n            </p>\n            <p>\n                Before retraining the model, data must be split into train and validation. To do so, created an image datastore for the images with their subfolders, which will treat the foldersâ€™ names as a label source. Following that, data were with a 70-30 ratio ensuring that the split is randomized, the ratio was used based on research provided by the University of Texas which says that the model performs best when a 70-80% split is used for training and 30-20% of the data is used for validation [7].\n            </p>\n        </>\n    );\n}\n"],"mappings":";;;AAAA,eAAe,SAASA,sBAAsBA,CAAA,EAAG;EAC7C,oBACIC,OAAA,CAAAC,SAAA;IAAAC,QAAA,gBACIF,OAAA;MAAAE,QAAA,gBACIF,OAAA;QAAAE,QAAA,EAAG;MAAQ;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,ssBAMnB;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAMH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAOH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAOH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAIH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAKH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,gBACIF,OAAA;QAAAE,QAAA,EAAG;MAAW;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG,CAAC,smBAKtB;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAMH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC,eACJN,OAAA;MAAAE,QAAA,EAAG;IAEH;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC;EAAA,eACN,CAAC;AAEX;AAACC,EAAA,GAhEuBR,sBAAsB;AAAA,IAAAQ,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}