{"ast":null,"code":"var _jsxFileName = \"/Users/rashed.alaleeli/Documents/GitHub/portfolio-react/src/Pages/ObjectDetection.js\";\nimport TopTitle from \"../container/ProjectPages/TopTitle\";\nimport LeftColumn from \"../container/ProjectPages/LeftColumn\";\nimport RightColumn from \"../container/ProjectPages/RightColumn\";\nimport HorizontalLine from \"../components/Lines/HorizontalLine\";\nimport { motion } from \"framer-motion\";\nimport { Button } from \"@nextui-org/react\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport default function ObjectDetection() {\n  return /*#__PURE__*/_jsxDEV(motion.main, {\n    initial: {\n      x: 1000,\n      opacity: 0.3\n    },\n    animate: {\n      x: 0,\n      opacity: 1\n    },\n    exit: {\n      x: 500,\n      opacity: 0\n    },\n    transition: {\n      type: \"tween\",\n      stiffness: 160,\n      duration: 0.5\n    },\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"container mx-auto pt-12 min-h-screen\",\n      children: [/*#__PURE__*/_jsxDEV(TopTitle, {\n        title: \"Traffic Detection using YOLOv5.\",\n        date: \"Oct 18, 2023\",\n        category: \"Computer Vision /Object detection\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 22,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(HorizontalLine, {\n        width: \"3/4\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 27,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"flex flex-col md:flex-row gap-0 mt-3\",\n        children: [/*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"w-full md:w-1/3 text-left px-4 mr-2\",\n          children: [/*#__PURE__*/_jsxDEV(LeftColumn, {\n            module: \"Computer Vision\",\n            objective: \"To accurately and efficiently identify and classify cars, buses, trucks, bicycles, and pedestrians within a given scene, enabling enhanced safety and traffic management\",\n            tools: \"YOLO, open CV, and streamlit\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 31,\n            columnNumber: 25\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"flex justify-center mt-5 mb-5\",\n            children: /*#__PURE__*/_jsxDEV(\"a\", {\n              href: \"https://traffic-detection.streamlit.app\",\n              target: \"_blank\",\n              rel: \"noreferrer\",\n              children: /*#__PURE__*/_jsxDEV(Button, {\n                className: \"bg-gray-true-300\",\n                variant: \"shadow\",\n                children: \"Try the model\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 38,\n                columnNumber: 33\n              }, this)\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 37,\n              columnNumber: 29\n            }, this)\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 36,\n            columnNumber: 25\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 30,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(RightColumn, {\n          children: [\"In the hustle and bustle of our modern world, the way we manage traffic has become an increasingly pressing challenge. Luckily, we have a secret weapon: computer vision. Imagine if our cameras could not only record traffic but also understand it. That's where traffic object detection comes into play. It's all about training machines to spot and classify cars, buses, trucks, and even pedestrians in real-time, making our roads safer and more efficient.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 48,\n            columnNumber: 25\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 48,\n            columnNumber: 30\n          }, this), \"The dataset used to train the models was provided by the University of Oxford, it consists of 17 different types of popular flowers in the UK, each with 80 images, making it a total of 1360 images, and all images have different characteristics including texture, shape, and colors [5]. All of the images will be used for the classification task, whereas only the Daffodil flower will be used for the segmentation.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 54,\n            columnNumber: 25\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 54,\n            columnNumber: 30\n          }, this), \"The DarkNet-53 model was used and retrained on 17 flower species to perform the task of image classification. However, to perform the task of image segmentation a new CNN were built and it consists of 4 main components including, input layer, downsampling layers, upsampling layers, and a classification layer.\", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 58,\n            columnNumber: 25\n          }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 58,\n            columnNumber: 30\n          }, this), \"The classification network was hard to train and computationally expensive, due to the high number of training data. However, it achieved a high accuracy of 89.22% when testing it on the validation data. Training the segmentation network was faster due less images being trained, and achieved an accuracy of 88.09% on training data and 81.101% on unseen data.\"]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 46,\n          columnNumber: 21\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 29,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 20,\n      columnNumber: 13\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 10,\n    columnNumber: 9\n  }, this);\n}\n_c = ObjectDetection;\nvar _c;\n$RefreshReg$(_c, \"ObjectDetection\");","map":{"version":3,"names":["TopTitle","LeftColumn","RightColumn","HorizontalLine","motion","Button","jsxDEV","_jsxDEV","ObjectDetection","main","initial","x","opacity","animate","exit","transition","type","stiffness","duration","children","className","title","date","category","fileName","_jsxFileName","lineNumber","columnNumber","width","module","objective","tools","href","target","rel","variant","_c","$RefreshReg$"],"sources":["/Users/rashed.alaleeli/Documents/GitHub/portfolio-react/src/Pages/ObjectDetection.js"],"sourcesContent":["import TopTitle from \"../container/ProjectPages/TopTitle\";\nimport LeftColumn from \"../container/ProjectPages/LeftColumn\";\nimport RightColumn from \"../container/ProjectPages/RightColumn\";\nimport HorizontalLine from \"../components/Lines/HorizontalLine\";\nimport { motion } from \"framer-motion\";\nimport { Button } from \"@nextui-org/react\";\n\nexport default function ObjectDetection() {\n    return (\n        <motion.main\n            initial={{ x: 1000, opacity: 0.3 }}\n            animate={{ x: 0, opacity: 1 }}\n            exit={{ x: 500, opacity: 0 }}\n            transition={{ \n            type:\"tween\",\n            stiffness: 160,\n            duration: 0.5, \n            }}\n        >\n            <div className=\"container mx-auto pt-12 min-h-screen\">\n                \n                <TopTitle \n                    title=\"Traffic Detection using YOLOv5.\" \n                    date=\"Oct 18, 2023\" \n                    category=\"Computer Vision /Object detection\" />\n                \n                <HorizontalLine width=\"3/4\" />\n\n                <div className=\"flex flex-col md:flex-row gap-0 mt-3\">\n                    <div className=\"w-full md:w-1/3 text-left px-4 mr-2\">\n                        <LeftColumn \n                            module=\"Computer Vision\" \n                            objective=\"To accurately and efficiently identify and classify cars, buses, trucks, bicycles, and pedestrians within a given scene, enabling enhanced safety and traffic management\" \n                            tools=\"YOLO, open CV, and streamlit\"/>\n                        \n                        <div className=\"flex justify-center mt-5 mb-5\">\n                            <a href=\"https://traffic-detection.streamlit.app\" target=\"_blank\" rel=\"noreferrer\">\n                                <Button className=\"bg-gray-true-300\" variant='shadow'>\n                                    Try the model\n                                </Button>\n                            </a>\n                        </div>\n\n                    </div>\n\n                    <RightColumn >\n                        In the hustle and bustle of our modern world, the way we manage traffic has become an increasingly pressing challenge. Luckily, we have a secret weapon: computer vision. Imagine if our cameras could not only record traffic but also understand it. That's where traffic object detection comes into play. It's all about training machines to spot and classify cars, buses, trucks, and even pedestrians in real-time, making our roads safer and more efficient.\n                        <br/><br/>\n                        The dataset used to train the models was provided by the University of Oxford, \n                        it consists of 17 different types of popular flowers in the UK, each with 80 images, \n                        making it a total of 1360 images, and all images have different characteristics including \n                        texture, shape, and colors [5]. All of the images will be used for the classification task, \n                        whereas only the Daffodil flower will be used for the segmentation.\n                        <br/><br/>\n                        The DarkNet-53 model was used and retrained on 17 flower species to perform the task of image classification. \n                        However, to perform the task of image segmentation a new CNN were built and it consists of 4 main components \n                        including, input layer, downsampling layers, upsampling layers, and a classification layer.\n                        <br/><br/>\n                        The classification network was hard to train and computationally expensive, \n                        due to the high number of training data. However, it achieved a high accuracy of 89.22% when testing it on the validation data.\n                        Training the segmentation network was faster due less images being trained,\n                        and achieved an accuracy of 88.09% on training data and 81.101% on unseen data.\n                    </RightColumn>\n                    \n                </div>\n            </div>\n\n        </motion.main>\n    )\n}"],"mappings":";AAAA,OAAOA,QAAQ,MAAM,oCAAoC;AACzD,OAAOC,UAAU,MAAM,sCAAsC;AAC7D,OAAOC,WAAW,MAAM,uCAAuC;AAC/D,OAAOC,cAAc,MAAM,oCAAoC;AAC/D,SAASC,MAAM,QAAQ,eAAe;AACtC,SAASC,MAAM,QAAQ,mBAAmB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE3C,eAAe,SAASC,eAAeA,CAAA,EAAG;EACtC,oBACID,OAAA,CAACH,MAAM,CAACK,IAAI;IACRC,OAAO,EAAE;MAAEC,CAAC,EAAE,IAAI;MAAEC,OAAO,EAAE;IAAI,CAAE;IACnCC,OAAO,EAAE;MAAEF,CAAC,EAAE,CAAC;MAAEC,OAAO,EAAE;IAAE,CAAE;IAC9BE,IAAI,EAAE;MAAEH,CAAC,EAAE,GAAG;MAAEC,OAAO,EAAE;IAAE,CAAE;IAC7BG,UAAU,EAAE;MACZC,IAAI,EAAC,OAAO;MACZC,SAAS,EAAE,GAAG;MACdC,QAAQ,EAAE;IACV,CAAE;IAAAC,QAAA,eAEFZ,OAAA;MAAKa,SAAS,EAAC,sCAAsC;MAAAD,QAAA,gBAEjDZ,OAAA,CAACP,QAAQ;QACLqB,KAAK,EAAC,iCAAiC;QACvCC,IAAI,EAAC,cAAc;QACnBC,QAAQ,EAAC;MAAmC;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC,eAEnDpB,OAAA,CAACJ,cAAc;QAACyB,KAAK,EAAC;MAAK;QAAAJ,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAE,CAAC,eAE9BpB,OAAA;QAAKa,SAAS,EAAC,sCAAsC;QAAAD,QAAA,gBACjDZ,OAAA;UAAKa,SAAS,EAAC,qCAAqC;UAAAD,QAAA,gBAChDZ,OAAA,CAACN,UAAU;YACP4B,MAAM,EAAC,iBAAiB;YACxBC,SAAS,EAAC,0KAA0K;YACpLC,KAAK,EAAC;UAA8B;YAAAP,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAC,CAAC,eAE1CpB,OAAA;YAAKa,SAAS,EAAC,+BAA+B;YAAAD,QAAA,eAC1CZ,OAAA;cAAGyB,IAAI,EAAC,yCAAyC;cAACC,MAAM,EAAC,QAAQ;cAACC,GAAG,EAAC,YAAY;cAAAf,QAAA,eAC9EZ,OAAA,CAACF,MAAM;gBAACe,SAAS,EAAC,kBAAkB;gBAACe,OAAO,EAAC,QAAQ;gBAAAhB,QAAA,EAAC;cAEtD;gBAAAK,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAQ;YAAC;cAAAH,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OACV;UAAC;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACH,CAAC;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAEL,CAAC,eAENpB,OAAA,CAACL,WAAW;UAAAiB,QAAA,GAAE,wcAEV,eAAAZ,OAAA;YAAAiB,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAI,CAAC,eAAApB,OAAA;YAAAiB,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAI,CAAC,iaAMV,eAAApB,OAAA;YAAAiB,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAI,CAAC,eAAApB,OAAA;YAAAiB,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAI,CAAC,0TAIV,eAAApB,OAAA;YAAAiB,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAI,CAAC,eAAApB,OAAA;YAAAiB,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAI,CAAC,2WAKd;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAa,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAEb,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACL;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAEG,CAAC;AAEtB;AAACS,EAAA,GA9DuB5B,eAAe;AAAA,IAAA4B,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}